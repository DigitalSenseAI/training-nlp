{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e92e35c-425f-4724-ab63-b1c782c48ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalamos los paquetes necesarios\n",
    "%pip install pysqlite3\n",
    "%pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e57162c-78f2-4c7d-af65-d2296b93bf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "__import__('pysqlite3')\n",
    "import sys\n",
    "sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')\n",
    "\n",
    "import os\n",
    "import chromadb\n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', 1000)\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d7412de-766e-4271-949d-7ff5bdbeef00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seteamos variables\n",
    "chroma_db_path = \"../chroma_db\"\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "collection_name = \"Montes_del_Plata\"\n",
    "directory = '../documents'\n",
    "OPENAI_API_KEY = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bd32b8b-8b1a-464b-8e7a-21a0ad3dd01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una base de datos vectorial local con Chroma\n",
    "client_chroma = chromadb.PersistentClient(path=chroma_db_path)\n",
    "embedding_function = OpenAIEmbeddingFunction(api_key=OPENAI_API_KEY, model_name=EMBEDDING_MODEL)\n",
    "collection = client_chroma.create_collection(name=collection_name, \n",
    "                                             metadata={\"hnsw:space\": \"cosine\"}, \n",
    "                                             embedding_function=embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49c7c77a-c44a-4e93-9953-f2f0694ddf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos los documentos a guardar en la base de datos vectorial\n",
    "\n",
    "docs_name = ['document_0', 'document_1', 'document_2', 'document_3', 'document_4', 'document_5', 'document_6', 'document_7', 'document_8',\n",
    " 'document_9', 'document_10', 'document_11', 'document_12', 'document_13', 'document_14', 'document_15_1', 'document_15_2', 'document_15_3', \n",
    " 'document_15_4', 'document_15_5', 'document_15_6', 'document_15_7', 'document_15_8', 'document_16_1', 'document_16_2', 'document_17_1', \n",
    " 'document_17_2', 'document_17_3', 'document_17_4', 'document_18_1', 'document_18_2', 'document_18_3', 'document_19'] \n",
    "documents = {}\n",
    "\n",
    "for doc in docs_name:\n",
    "    file_path = os.path.join(directory, doc+\".txt\")\n",
    "    with open(file_path, 'r') as file:\n",
    "        documents[doc] = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f1a93bd-eea7-4999-afc2-239202d53af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos metadata para guardar con los documentos\n",
    "# la estructura de los datos es una lista de diccionarios\n",
    "metadata = []\n",
    "\n",
    "departamento = ['Forestal']*12 + ['Planta']*(len(documents.keys())-12)\n",
    "nombre_doc = ['P_LOGT_01: TRANSPORTE DE MADERA']*12 + ['Instrucciones de operación de procesos: Blanqueo']*(len(documents.keys())-12)\n",
    "capitulo = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '0', '1', '2', '3', '3', '3', '3', '3', '3', '3', '3', '4', '4', '5', '5', '5', '5', '6', '6', '6', '7']\n",
    "\n",
    "# las 3 listas anteriores deberian tener el mismo largo\n",
    "for i in range(len(departamento)):\n",
    "    metadata.append(\n",
    "        {'departamento' : departamento[i],\n",
    "         'nombre_documento' : nombre_doc[i],\n",
    "         'capitulo' : capitulo[i]}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "907be7a2-f473-4737-bbd4-a7b9f0070b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almacenamos los datos en la colección\n",
    "# Dejamos que los embeddings de cada documento los genere Chroma \n",
    "# haciendo una llamada al modelo de embedding de OpenAI que elegimos al comienzo\n",
    "\n",
    "collection.add(\n",
    "    ids=[str(num) for num in range(len(documents.keys()))],\n",
    "    documents=list(documents.values()),\n",
    "    metadatas=metadata\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d978a24b-78c0-4e4f-b235-a4caeacbb7a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Collection(id=e97c9ab4-4c0d-467f-80c8-02e1d948e120, name=Montes_del_Plata)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_chroma.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57247909-1c80-4d36-aad0-faf28dfa0d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection = client_chroma.get_collection(name=\"Montes_del_Plata\")\n",
    "collection.count()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "microsoft": {
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
